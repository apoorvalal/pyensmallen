{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc9fb1a2",
   "metadata": {},
   "source": [
    "# Benchmarking `pyensmallen` for m-estimation\n",
    "\n",
    "LBFGS works well for most smooth convex functions, notably a convex loss such as a likelihood. I generally find that optimization convergence is so fast that bootstrapping the entire procedure may be feasible.\n",
    "\n",
    "Benchmarks against several popular optimization libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11982416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyensmallen\n",
    "import scipy.optimize\n",
    "import cvxpy as cp\n",
    "from scipy.special import expit\n",
    "import time\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88d6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import functools\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5356965f",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2785ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51639859 0.94598022 0.23380001 0.55162275 0.97811966 0.24254699\n",
      " 0.64702478 0.70271041 0.26476461 0.77362184 0.7817448  0.36874977\n",
      " 0.72697004 0.06518613 0.72705723 0.38967364 0.03826155 0.39386005\n",
      " 0.0438693  0.72142769]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n, k = 1_000_000, 20\n",
    "\n",
    "# Linear Regression Data\n",
    "X_linear = np.random.randn(n, k)\n",
    "print(true_params_linear := np.random.rand(k))\n",
    "y_linear = X_linear @ true_params_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6836c13a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84089c27",
   "metadata": {},
   "source": [
    "### pyensmallen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3df0ec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_objective(params, gradient, X, y):\n",
    "    params = params.reshape(-1, 1)\n",
    "    residuals = X @ params - y.reshape(-1, 1)\n",
    "    objective = np.sum(residuals**2)\n",
    "    grad = 2 * X.T @ residuals\n",
    "    gradient[:] = grad.flatten()\n",
    "    return objective\n",
    "\n",
    "linear_start = np.random.rand(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3483674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.25 s, sys: 182 ms, total: 6.43 s\n",
      "Wall time: 451 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer = pyensmallen.L_BFGS()\n",
    "result_linear_ens = optimizer.optimize(\n",
    "    lambda params, gradient: linear_objective(params, gradient, X_linear, y_linear),\n",
    "    linear_start,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd35fb",
   "metadata": {},
   "source": [
    "### scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1318ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 34s, sys: 3.01 s, total: 1min 37s\n",
      "Wall time: 6.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_linear_scipy = scipy.optimize.minimize(\n",
    "    fun=lambda b: np.sum((X_linear @ b - y_linear) ** 2),\n",
    "    x0=linear_start,\n",
    "    jac=lambda b: 2 * X_linear.T @ (X_linear @ b - y_linear),\n",
    ").x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9edb7e",
   "metadata": {},
   "source": [
    "### cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16b477c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.3 s, sys: 3.88 s, total: 15.2 s\n",
      "Wall time: 15.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(3.813432269764509e-16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "b_linear = cp.Variable(k)\n",
    "cost_linear = cp.norm(X_linear @ b_linear - y_linear, p=2) ** 2 / n\n",
    "prob_linear = cp.Problem(cp.Minimize(cost_linear))\n",
    "prob_linear.solve(solver=cp.SCS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299e3f80",
   "metadata": {},
   "source": [
    "### jax + optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0f4b82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.92 s, sys: 127 ms, total: 5.05 s\n",
      "Wall time: 5.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_jnp, y_jnp = jnp.array(X_linear), jnp.array(y_linear)\n",
    "\n",
    "def compute_loss(beta):\n",
    "    y_pred = jnp.dot(X_jnp, beta)\n",
    "    loss = jnp.mean((y_pred - y_jnp) ** 2)\n",
    "    return loss\n",
    "\n",
    "params = jnp.array(linear_start)\n",
    "solver = optax.lbfgs()\n",
    "opt_state = solver.init(params)\n",
    "value_and_grad = optax.value_and_grad_from_state(compute_loss)\n",
    "\n",
    "# Optimization loop\n",
    "for i in range(10):\n",
    "    value, grad = value_and_grad(params, state=opt_state)\n",
    "    updates, opt_state = solver.update(\n",
    "        grad, opt_state, params, value=value, grad=grad, value_fn=compute_loss\n",
    "    )\n",
    "    params = optax.apply_updates(params, updates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53501bbc",
   "metadata": {},
   "source": [
    "### closed form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bd523d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.3 s, sys: 48.2 ms, total: 1.35 s\n",
      "Wall time: 439 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np_lstsq_sol = np.linalg.lstsq(X_linear, y_linear, rcond=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43383527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.96 s, sys: 370 ms, total: 8.33 s\n",
      "Wall time: 1.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sm_lstsq_sol = sm.OLS(y_linear, X_linear).fit().params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f709558",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2794ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>ensmallen</th>\n",
       "      <th>scipy</th>\n",
       "      <th>cvxpy</th>\n",
       "      <th>jax</th>\n",
       "      <th>np_lstsq</th>\n",
       "      <th>sm_lstsq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.516399</td>\n",
       "      <td>0.516399</td>\n",
       "      <td>0.516399</td>\n",
       "      <td>0.516399</td>\n",
       "      <td>0.516396</td>\n",
       "      <td>0.516399</td>\n",
       "      <td>0.516399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.945980</td>\n",
       "      <td>0.945980</td>\n",
       "      <td>0.945980</td>\n",
       "      <td>0.945980</td>\n",
       "      <td>0.945986</td>\n",
       "      <td>0.945980</td>\n",
       "      <td>0.945980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.233798</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.233800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.551623</td>\n",
       "      <td>0.551623</td>\n",
       "      <td>0.551623</td>\n",
       "      <td>0.551623</td>\n",
       "      <td>0.551621</td>\n",
       "      <td>0.551623</td>\n",
       "      <td>0.551623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.978120</td>\n",
       "      <td>0.978120</td>\n",
       "      <td>0.978120</td>\n",
       "      <td>0.978120</td>\n",
       "      <td>0.978121</td>\n",
       "      <td>0.978120</td>\n",
       "      <td>0.978120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.242547</td>\n",
       "      <td>0.242547</td>\n",
       "      <td>0.242547</td>\n",
       "      <td>0.242547</td>\n",
       "      <td>0.242548</td>\n",
       "      <td>0.242547</td>\n",
       "      <td>0.242547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.647025</td>\n",
       "      <td>0.647025</td>\n",
       "      <td>0.647025</td>\n",
       "      <td>0.647025</td>\n",
       "      <td>0.647029</td>\n",
       "      <td>0.647025</td>\n",
       "      <td>0.647025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.702710</td>\n",
       "      <td>0.702710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.264765</td>\n",
       "      <td>0.264765</td>\n",
       "      <td>0.264765</td>\n",
       "      <td>0.264765</td>\n",
       "      <td>0.264757</td>\n",
       "      <td>0.264765</td>\n",
       "      <td>0.264765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.773622</td>\n",
       "      <td>0.773622</td>\n",
       "      <td>0.773622</td>\n",
       "      <td>0.773622</td>\n",
       "      <td>0.773628</td>\n",
       "      <td>0.773622</td>\n",
       "      <td>0.773622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.781745</td>\n",
       "      <td>0.781745</td>\n",
       "      <td>0.781745</td>\n",
       "      <td>0.781745</td>\n",
       "      <td>0.781745</td>\n",
       "      <td>0.781745</td>\n",
       "      <td>0.781745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.368750</td>\n",
       "      <td>0.368750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.726970</td>\n",
       "      <td>0.726970</td>\n",
       "      <td>0.726970</td>\n",
       "      <td>0.726970</td>\n",
       "      <td>0.726975</td>\n",
       "      <td>0.726970</td>\n",
       "      <td>0.726970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.065186</td>\n",
       "      <td>0.065186</td>\n",
       "      <td>0.065186</td>\n",
       "      <td>0.065186</td>\n",
       "      <td>0.065185</td>\n",
       "      <td>0.065186</td>\n",
       "      <td>0.065186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.727051</td>\n",
       "      <td>0.727057</td>\n",
       "      <td>0.727057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.389674</td>\n",
       "      <td>0.389674</td>\n",
       "      <td>0.389674</td>\n",
       "      <td>0.389674</td>\n",
       "      <td>0.389674</td>\n",
       "      <td>0.389674</td>\n",
       "      <td>0.389674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.038262</td>\n",
       "      <td>0.038262</td>\n",
       "      <td>0.038262</td>\n",
       "      <td>0.038262</td>\n",
       "      <td>0.038263</td>\n",
       "      <td>0.038262</td>\n",
       "      <td>0.038262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.393860</td>\n",
       "      <td>0.393860</td>\n",
       "      <td>0.393860</td>\n",
       "      <td>0.393860</td>\n",
       "      <td>0.393865</td>\n",
       "      <td>0.393860</td>\n",
       "      <td>0.393860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.043869</td>\n",
       "      <td>0.043869</td>\n",
       "      <td>0.043869</td>\n",
       "      <td>0.043869</td>\n",
       "      <td>0.043871</td>\n",
       "      <td>0.043869</td>\n",
       "      <td>0.043869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.721428</td>\n",
       "      <td>0.721428</td>\n",
       "      <td>0.721428</td>\n",
       "      <td>0.721428</td>\n",
       "      <td>0.721435</td>\n",
       "      <td>0.721428</td>\n",
       "      <td>0.721428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        true  ensmallen     scipy     cvxpy       jax  np_lstsq  sm_lstsq\n",
       "0   0.516399   0.516399  0.516399  0.516399  0.516396  0.516399  0.516399\n",
       "1   0.945980   0.945980  0.945980  0.945980  0.945986  0.945980  0.945980\n",
       "2   0.233800   0.233800  0.233800  0.233800  0.233798  0.233800  0.233800\n",
       "3   0.551623   0.551623  0.551623  0.551623  0.551621  0.551623  0.551623\n",
       "4   0.978120   0.978120  0.978120  0.978120  0.978121  0.978120  0.978120\n",
       "5   0.242547   0.242547  0.242547  0.242547  0.242548  0.242547  0.242547\n",
       "6   0.647025   0.647025  0.647025  0.647025  0.647029  0.647025  0.647025\n",
       "7   0.702710   0.702710  0.702710  0.702710  0.702710  0.702710  0.702710\n",
       "8   0.264765   0.264765  0.264765  0.264765  0.264757  0.264765  0.264765\n",
       "9   0.773622   0.773622  0.773622  0.773622  0.773628  0.773622  0.773622\n",
       "10  0.781745   0.781745  0.781745  0.781745  0.781745  0.781745  0.781745\n",
       "11  0.368750   0.368750  0.368750  0.368750  0.368750  0.368750  0.368750\n",
       "12  0.726970   0.726970  0.726970  0.726970  0.726975  0.726970  0.726970\n",
       "13  0.065186   0.065186  0.065186  0.065186  0.065185  0.065186  0.065186\n",
       "14  0.727057   0.727057  0.727057  0.727057  0.727051  0.727057  0.727057\n",
       "15  0.389674   0.389674  0.389674  0.389674  0.389674  0.389674  0.389674\n",
       "16  0.038262   0.038262  0.038262  0.038262  0.038263  0.038262  0.038262\n",
       "17  0.393860   0.393860  0.393860  0.393860  0.393865  0.393860  0.393860\n",
       "18  0.043869   0.043869  0.043869  0.043869  0.043871  0.043869  0.043869\n",
       "19  0.721428   0.721428  0.721428  0.721428  0.721435  0.721428  0.721428"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_df = pd.DataFrame({\n",
    "    \"true\": true_params_linear,\n",
    "    \"ensmallen\": result_linear_ens,\n",
    "    \"scipy\": result_linear_scipy,\n",
    "    \"cvxpy\": b_linear.value,\n",
    "    \"jax\": params,\n",
    "    \"np_lstsq\": np_lstsq_sol,\n",
    "    \"sm_lstsq\": sm_lstsq_sol,\n",
    "})\n",
    "lin_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c05ef61",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d5449a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24622957 0.77088703 0.99525454 0.92697675 0.85896413 0.96032642\n",
      " 0.28103909 0.74634994 0.37044719 0.91379069 0.76225183 0.34217879\n",
      " 0.09916425 0.81927817 0.48192179 0.49853671 0.91310665 0.24428751\n",
      " 0.38247698 0.75367349]\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Data\n",
    "n, k = 10_000, 20\n",
    "X_logistic = np.random.randn(n, k)\n",
    "print(true_params_logistic := np.random.rand(k))\n",
    "p = expit(X_logistic @ true_params_logistic)\n",
    "y_logistic = np.random.binomial(1, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7b3e3e",
   "metadata": {},
   "source": [
    "### pyensmallen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8446939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_objective(params, gradient, X, y):\n",
    "    z = X @ params\n",
    "    h = expit(z)\n",
    "    objective = -np.sum(y * np.log(h) + (1 - y) * np.log1p(-h))\n",
    "    if np.isnan(objective):\n",
    "        objective = np.inf\n",
    "    grad = X.T @ (h - y)\n",
    "    gradient[:] = grad\n",
    "    return objective\n",
    "\n",
    "logistic_start = np.random.rand(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "add9a17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.43 ms, sys: 27 μs, total: 9.45 ms\n",
      "Wall time: 9.02 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_logistic2 = np.ascontiguousarray(\n",
    "    X_logistic\n",
    ")  # Ensure C-contiguous array for better performance\n",
    "y_logistic2 = y_logistic.ravel()\n",
    "\n",
    "optimizer = pyensmallen.L_BFGS()\n",
    "result_logistic_ens = optimizer.optimize(\n",
    "    lambda params, gradient: logistic_objective(\n",
    "        params, gradient, X_logistic2, y_logistic2\n",
    "    ),\n",
    "    logistic_start,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb60d2da",
   "metadata": {},
   "source": [
    "### scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dee0bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.8 ms, sys: 23 μs, total: 38.8 ms\n",
      "Wall time: 38 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:4: RuntimeWarning: divide by zero encountered in log\n",
      "<timed exec>:4: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_logistic_scipy = scipy.optimize.minimize(\n",
    "    fun=lambda b: -np.sum(\n",
    "        y_logistic * np.log(expit(X_logistic @ b))\n",
    "        + (1 - y_logistic) * np.log(1 - expit(X_logistic @ b))\n",
    "    ),\n",
    "    x0=logistic_start,\n",
    "    jac=lambda b: X_logistic.T @ (expit(X_logistic @ b) - y_logistic),\n",
    ").x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00054738",
   "metadata": {},
   "source": [
    "### cvxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d90380c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.19 s, sys: 23.2 ms, total: 1.21 s\n",
      "Wall time: 1.21 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(-3596.331511780124)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "b_logistic = cp.Variable(k)\n",
    "log_likelihood = cp.sum(\n",
    "    cp.multiply(y_logistic, X_logistic @ b_logistic)\n",
    "    - cp.logistic(X_logistic @ b_logistic)\n",
    ")\n",
    "prob_logistic = cp.Problem(cp.Maximize(log_likelihood))\n",
    "prob_logistic.solve(solver=cp.SCS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38794806",
   "metadata": {},
   "source": [
    "### statsmodels\n",
    "\n",
    "does IRLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9dad1419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.359633\n",
      "         Iterations 7\n",
      "CPU times: user 247 ms, sys: 1.62 ms, total: 248 ms\n",
      "Wall time: 38.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sm_logit_res = sm.Logit(y_logistic, X_logistic).fit().params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b4f9925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.34 s, sys: 71.9 ms, total: 4.41 s\n",
      "Wall time: 4.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_jnp, y_jnp = jnp.array(X_logistic), jnp.array(y_logistic)\n",
    "\n",
    "def logistic_likelihood(beta):\n",
    "    z = jnp.dot(X_jnp, beta)\n",
    "    h = jax.scipy.special.expit(z)\n",
    "    loss = -jnp.sum(y_jnp * jnp.log(h) + (1 - y_jnp) * jnp.log1p(-h))\n",
    "    return loss\n",
    "\n",
    "params = jnp.array(linear_start)\n",
    "solver = optax.lbfgs()\n",
    "opt_state = solver.init(params)\n",
    "value_and_grad = optax.value_and_grad_from_state(logistic_likelihood)\n",
    "\n",
    "# Optimization loop\n",
    "for i in range(10):\n",
    "    value, grad = value_and_grad(params, state=opt_state)\n",
    "    updates, opt_state = solver.update(\n",
    "        grad, opt_state, params, value=value, grad=grad, value_fn=logistic_likelihood\n",
    "    )\n",
    "    params = optax.apply_updates(params, updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975cbb20",
   "metadata": {},
   "source": [
    "## comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06085d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>ensmallen</th>\n",
       "      <th>scipy</th>\n",
       "      <th>cvxpy</th>\n",
       "      <th>jax</th>\n",
       "      <th>sm_logit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.246230</td>\n",
       "      <td>0.266128</td>\n",
       "      <td>0.266128</td>\n",
       "      <td>0.266125</td>\n",
       "      <td>0.214509</td>\n",
       "      <td>0.266128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.770887</td>\n",
       "      <td>0.772562</td>\n",
       "      <td>0.772562</td>\n",
       "      <td>0.772553</td>\n",
       "      <td>0.750707</td>\n",
       "      <td>0.772562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.995255</td>\n",
       "      <td>0.992790</td>\n",
       "      <td>0.992790</td>\n",
       "      <td>0.992778</td>\n",
       "      <td>1.049312</td>\n",
       "      <td>0.992790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.926977</td>\n",
       "      <td>0.950981</td>\n",
       "      <td>0.950981</td>\n",
       "      <td>0.950970</td>\n",
       "      <td>0.993830</td>\n",
       "      <td>0.950981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.858964</td>\n",
       "      <td>0.802078</td>\n",
       "      <td>0.802078</td>\n",
       "      <td>0.802069</td>\n",
       "      <td>0.770684</td>\n",
       "      <td>0.802078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.960326</td>\n",
       "      <td>0.968322</td>\n",
       "      <td>0.968322</td>\n",
       "      <td>0.968311</td>\n",
       "      <td>1.030593</td>\n",
       "      <td>0.968322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.281039</td>\n",
       "      <td>0.259412</td>\n",
       "      <td>0.259412</td>\n",
       "      <td>0.259409</td>\n",
       "      <td>0.197726</td>\n",
       "      <td>0.259412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.746350</td>\n",
       "      <td>0.721670</td>\n",
       "      <td>0.721670</td>\n",
       "      <td>0.721662</td>\n",
       "      <td>0.730997</td>\n",
       "      <td>0.721670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.370447</td>\n",
       "      <td>0.374674</td>\n",
       "      <td>0.374674</td>\n",
       "      <td>0.374670</td>\n",
       "      <td>0.383463</td>\n",
       "      <td>0.374674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.913791</td>\n",
       "      <td>0.909638</td>\n",
       "      <td>0.909638</td>\n",
       "      <td>0.909628</td>\n",
       "      <td>0.929301</td>\n",
       "      <td>0.909638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.762252</td>\n",
       "      <td>0.769224</td>\n",
       "      <td>0.769224</td>\n",
       "      <td>0.769216</td>\n",
       "      <td>0.767441</td>\n",
       "      <td>0.769224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.342179</td>\n",
       "      <td>0.345154</td>\n",
       "      <td>0.345154</td>\n",
       "      <td>0.345151</td>\n",
       "      <td>0.337069</td>\n",
       "      <td>0.345154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.099164</td>\n",
       "      <td>0.096116</td>\n",
       "      <td>0.096116</td>\n",
       "      <td>0.096115</td>\n",
       "      <td>0.069483</td>\n",
       "      <td>0.096116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.819278</td>\n",
       "      <td>0.824307</td>\n",
       "      <td>0.824307</td>\n",
       "      <td>0.824298</td>\n",
       "      <td>0.809711</td>\n",
       "      <td>0.824307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.481922</td>\n",
       "      <td>0.480732</td>\n",
       "      <td>0.480732</td>\n",
       "      <td>0.480727</td>\n",
       "      <td>0.430237</td>\n",
       "      <td>0.480732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.498537</td>\n",
       "      <td>0.541618</td>\n",
       "      <td>0.541618</td>\n",
       "      <td>0.541611</td>\n",
       "      <td>0.516393</td>\n",
       "      <td>0.541618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.913107</td>\n",
       "      <td>0.875384</td>\n",
       "      <td>0.875384</td>\n",
       "      <td>0.875374</td>\n",
       "      <td>0.928213</td>\n",
       "      <td>0.875384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.244288</td>\n",
       "      <td>0.276439</td>\n",
       "      <td>0.276439</td>\n",
       "      <td>0.276436</td>\n",
       "      <td>0.204577</td>\n",
       "      <td>0.276439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.382477</td>\n",
       "      <td>0.346210</td>\n",
       "      <td>0.346210</td>\n",
       "      <td>0.346206</td>\n",
       "      <td>0.282821</td>\n",
       "      <td>0.346210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.753673</td>\n",
       "      <td>0.743372</td>\n",
       "      <td>0.743372</td>\n",
       "      <td>0.743363</td>\n",
       "      <td>0.707642</td>\n",
       "      <td>0.743372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        true  ensmallen     scipy     cvxpy       jax  sm_logit\n",
       "0   0.246230   0.266128  0.266128  0.266125  0.214509  0.266128\n",
       "1   0.770887   0.772562  0.772562  0.772553  0.750707  0.772562\n",
       "2   0.995255   0.992790  0.992790  0.992778  1.049312  0.992790\n",
       "3   0.926977   0.950981  0.950981  0.950970  0.993830  0.950981\n",
       "4   0.858964   0.802078  0.802078  0.802069  0.770684  0.802078\n",
       "5   0.960326   0.968322  0.968322  0.968311  1.030593  0.968322\n",
       "6   0.281039   0.259412  0.259412  0.259409  0.197726  0.259412\n",
       "7   0.746350   0.721670  0.721670  0.721662  0.730997  0.721670\n",
       "8   0.370447   0.374674  0.374674  0.374670  0.383463  0.374674\n",
       "9   0.913791   0.909638  0.909638  0.909628  0.929301  0.909638\n",
       "10  0.762252   0.769224  0.769224  0.769216  0.767441  0.769224\n",
       "11  0.342179   0.345154  0.345154  0.345151  0.337069  0.345154\n",
       "12  0.099164   0.096116  0.096116  0.096115  0.069483  0.096116\n",
       "13  0.819278   0.824307  0.824307  0.824298  0.809711  0.824307\n",
       "14  0.481922   0.480732  0.480732  0.480727  0.430237  0.480732\n",
       "15  0.498537   0.541618  0.541618  0.541611  0.516393  0.541618\n",
       "16  0.913107   0.875384  0.875384  0.875374  0.928213  0.875384\n",
       "17  0.244288   0.276439  0.276439  0.276436  0.204577  0.276439\n",
       "18  0.382477   0.346210  0.346210  0.346206  0.282821  0.346210\n",
       "19  0.753673   0.743372  0.743372  0.743363  0.707642  0.743372"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_df = pd.DataFrame(\n",
    "    {\n",
    "        \"true\": true_params_logistic,\n",
    "        \"ensmallen\": result_logistic_ens,\n",
    "        \"scipy\": result_logistic_scipy,\n",
    "        \"cvxpy\": b_logistic.value,\n",
    "        \"jax\": params,\n",
    "        \"sm_logit\": sm_logit_res,\n",
    "    }\n",
    ")\n",
    "logit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546244ad",
   "metadata": {},
   "source": [
    "## Poisson Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7c03a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21058295 0.37114233 0.11747555 0.85610033 0.10420509 0.38705405\n",
      " 0.85924089 0.35038735 0.99516334 0.38716221]\n"
     ]
    }
   ],
   "source": [
    "n, k = 100_000, 10\n",
    "# Poisson Regression Data\n",
    "X_poisson = np.random.randn(n, k)\n",
    "print(true_params_poisson := np.random.rand(k))\n",
    "lambda_ = np.exp(X_poisson @ true_params_poisson)\n",
    "y_poisson = np.random.poisson(lambda_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcf7888",
   "metadata": {},
   "source": [
    "## pyensmallen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba86a97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poisson_objective(params, gradient, X, y):\n",
    "    params = params.reshape(-1, 1)\n",
    "    y = y.reshape(-1, 1)\n",
    "    Xbeta = X @ params\n",
    "    lambda_ = np.exp(Xbeta)\n",
    "    objective = np.sum(lambda_ - np.multiply(y, np.log(lambda_)))\n",
    "    # Compute the gradient\n",
    "    grad = X.T @ (lambda_ - y)\n",
    "    gradient[:] = grad.ravel()\n",
    "    return objective\n",
    "\n",
    "poisson_start = np.random.rand(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4c87692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.49 s, sys: 7.38 ms, total: 1.49 s\n",
      "Wall time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer = pyensmallen.L_BFGS()\n",
    "result_poisson_ens = optimizer.optimize(\n",
    "    lambda params, gradient: poisson_objective(params, gradient, X_poisson, y_poisson),\n",
    "    poisson_start,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e851e198",
   "metadata": {},
   "source": [
    "### scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b00785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.57 s, sys: 4.37 ms, total: 8.57 s\n",
      "Wall time: 586 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_poisson_scipy = scipy.optimize.minimize(\n",
    "    fun=lambda b: np.sum(np.exp(X_poisson @ b) - y_poisson * (X_poisson @ b)),\n",
    "    x0=poisson_start,\n",
    "    jac=lambda b: X_poisson.T @ (np.exp(X_poisson @ b) - y_poisson),\n",
    ").x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67b81bc",
   "metadata": {},
   "source": [
    "### cvxpy\n",
    "\n",
    "fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "572fcfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# b_poisson = cp.Variable(k)\n",
    "# z = X_poisson @ b_poisson\n",
    "# cost_poisson = cp.sum(cp.exp(z) - cp.multiply(y_poisson, z)) / n\n",
    "# prob_poisson = cp.Problem(cp.Minimize(cost_poisson))\n",
    "# prob_poisson.solve(solver=cp.SCS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601a275b",
   "metadata": {},
   "source": [
    "Runs out of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50088af0",
   "metadata": {},
   "source": [
    "### statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e343e20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.383029\n",
      "         Iterations 28\n",
      "CPU times: user 7.08 s, sys: 13.5 ms, total: 7.09 s\n",
      "Wall time: 515 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sm_poisson_res = sm.Poisson(y_poisson, X_poisson).fit().params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dbc95c",
   "metadata": {},
   "source": [
    "## jax\n",
    "switch to adam since lbfgs performs poorly (!TODO why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "229f7d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.21 s, sys: 88.6 ms, total: 2.3 s\n",
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_jnp, y_jnp = jnp.array(X_poisson), jnp.array(y_poisson)\n",
    "\n",
    "def poisson_likelihood(beta):\n",
    "    z = jnp.dot(X_jnp, beta)\n",
    "    lambda_ = jnp.exp(z)\n",
    "    loss = jnp.sum(lambda_ - y_jnp * z)\n",
    "    return loss\n",
    "\n",
    "\n",
    "solver = optax.adam(1e-2)\n",
    "adam_params = jnp.array(poisson_start)\n",
    "opt_state = solver.init(adam_params)\n",
    "\n",
    "@jax.jit\n",
    "def update_step(params, opt_state):\n",
    "    loss, grads = jax.value_and_grad(poisson_likelihood)(params)\n",
    "    updates, opt_state = solver.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    adam_params, opt_state, loss = update_step(adam_params, opt_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df402d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true</th>\n",
       "      <th>ensmallen</th>\n",
       "      <th>scipy</th>\n",
       "      <th>sm_poisson</th>\n",
       "      <th>jax_adam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.210583</td>\n",
       "      <td>0.208376</td>\n",
       "      <td>0.208376</td>\n",
       "      <td>0.208376</td>\n",
       "      <td>0.208376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.371142</td>\n",
       "      <td>0.368691</td>\n",
       "      <td>0.368691</td>\n",
       "      <td>0.368691</td>\n",
       "      <td>0.368691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.117476</td>\n",
       "      <td>0.116927</td>\n",
       "      <td>0.116927</td>\n",
       "      <td>0.116927</td>\n",
       "      <td>0.116927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.856100</td>\n",
       "      <td>0.855668</td>\n",
       "      <td>0.855668</td>\n",
       "      <td>0.855668</td>\n",
       "      <td>0.855668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.104205</td>\n",
       "      <td>0.103997</td>\n",
       "      <td>0.103997</td>\n",
       "      <td>0.103997</td>\n",
       "      <td>0.103997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.387054</td>\n",
       "      <td>0.388284</td>\n",
       "      <td>0.388284</td>\n",
       "      <td>0.388284</td>\n",
       "      <td>0.388284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.859241</td>\n",
       "      <td>0.861597</td>\n",
       "      <td>0.861597</td>\n",
       "      <td>0.861597</td>\n",
       "      <td>0.861597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.350387</td>\n",
       "      <td>0.350552</td>\n",
       "      <td>0.350552</td>\n",
       "      <td>0.350552</td>\n",
       "      <td>0.350552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.995163</td>\n",
       "      <td>0.996572</td>\n",
       "      <td>0.996572</td>\n",
       "      <td>0.996572</td>\n",
       "      <td>0.996572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.387162</td>\n",
       "      <td>0.386803</td>\n",
       "      <td>0.386803</td>\n",
       "      <td>0.386803</td>\n",
       "      <td>0.386803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       true  ensmallen     scipy  sm_poisson  jax_adam\n",
       "0  0.210583   0.208376  0.208376    0.208376  0.208376\n",
       "1  0.371142   0.368691  0.368691    0.368691  0.368691\n",
       "2  0.117476   0.116927  0.116927    0.116927  0.116927\n",
       "3  0.856100   0.855668  0.855668    0.855668  0.855668\n",
       "4  0.104205   0.103997  0.103997    0.103997  0.103997\n",
       "5  0.387054   0.388284  0.388284    0.388284  0.388284\n",
       "6  0.859241   0.861597  0.861597    0.861597  0.861597\n",
       "7  0.350387   0.350552  0.350552    0.350552  0.350552\n",
       "8  0.995163   0.996572  0.996572    0.996572  0.996572\n",
       "9  0.387162   0.386803  0.386803    0.386803  0.386803"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi_df = pd.DataFrame(\n",
    "  {\n",
    "      \"true\": true_params_poisson,\n",
    "      \"ensmallen\": result_poisson_ens,\n",
    "      \"scipy\": result_poisson_scipy,\n",
    "      \"sm_poisson\": sm_poisson_res,\n",
    "      \"jax_adam\": adam_params,\n",
    "  }\n",
    ")\n",
    "poi_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "econometrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
