{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import pyensmallen\n",
    "import time\n",
    "import optax\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "key = jax.random.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters\n",
    "K = 4  # number of classes\n",
    "D = 10  # number of features\n",
    "N = 10_000  # number of samples\n",
    "\n",
    "# Generate true coefficients (K categories, last category is reference with zeros)\n",
    "true_coeffs = np.random.randn(D, K)\n",
    "true_coeffs[:, -1] = 0  # Set last category coefficients to zero\n",
    "\n",
    "# Generate features\n",
    "X = np.random.randn(N, D)\n",
    "\n",
    "# Generate probabilities and labels\n",
    "logits = X @ true_coeffs\n",
    "probs = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)\n",
    "y = np.array([np.random.choice(K, p=p) for p in probs])\n",
    "\n",
    "# Convert data to JAX arrays\n",
    "X_jax = jax.device_put(X)\n",
    "y_jax = jax.device_put(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pyensmallen + jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the multinomial logistic regression model\n",
    "def multinomial_logit(params, X):\n",
    "    full_params = jnp.column_stack([params.reshape(D, K - 1), jnp.zeros((D, 1))])\n",
    "    return jax.nn.log_softmax(X @ full_params, axis=1)\n",
    "\n",
    "\n",
    "# Define the loss function (negative log-likelihood)\n",
    "def loss(params, X, y):\n",
    "    logits = multinomial_logit(params, X)\n",
    "    return -jnp.mean(logits[jnp.arange(y.shape[0]), y])\n",
    "\n",
    "\n",
    "# Create JAX gradient function - autodiff!\n",
    "grad_loss = jax.grad(loss)\n",
    "\n",
    "\n",
    "# Define the objective function for pyensmallen\n",
    "def objective(params, gradient, X, y):\n",
    "    params_jax = jax.device_put(params.reshape(D, K - 1))\n",
    "    loss_value = loss(params_jax, X_jax, y_jax)\n",
    "    grad = grad_loss(params_jax, X_jax, y_jax)\n",
    "    gradient[:] = np.array(grad).flatten()\n",
    "    return float(loss_value)\n",
    "\n",
    "\n",
    "# Pyensmallen optimization\n",
    "start_time = time.time()\n",
    "optimizer = pyensmallen.L_BFGS()\n",
    "initial_params = np.random.randn(D * (K - 1))\n",
    "result_ens = optimizer.optimize(\n",
    "    lambda params, gradient: objective(params, gradient, X_jax, y_jax), initial_params\n",
    ")\n",
    "ens_time = time.time() - start_time\n",
    "estimated_coeffs_ens = np.column_stack([result_ens.reshape(D, K - 1), np.zeros((D, 1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JAX optimization with Optax\n",
    "start_time = time.time()\n",
    "initial_params = jnp.array(initial_params.reshape(D, K - 1))\n",
    "\n",
    "# Define the Optax optimizer (using Adam as an example)\n",
    "optimizer = optax.adam(learning_rate=0.01)\n",
    "opt_state = optimizer.init(initial_params)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def step(params, opt_state, X, y):\n",
    "    loss_value, grads = jax.value_and_grad(loss)(params, X, y)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state, params)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss_value\n",
    "\n",
    "\n",
    "params = initial_params\n",
    "for i in range(2000):\n",
    "    params, opt_state, _ = step(params, opt_state, X_jax, y_jax)\n",
    "\n",
    "estimated_coeffs_jax = jnp.column_stack([params, jnp.zeros((D, 1))])\n",
    "jax_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_coeffs.reshape(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.76405235,  1.81593705,  1.81090689],\n",
       "       [ 0.40015721,  0.42660712,  0.42548722],\n",
       "       [ 0.97873798,  0.9881251 ,  0.98618811],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [ 1.86755799,  1.86311812,  1.85787034],\n",
       "       [-0.97727788, -0.99712363, -0.99704129],\n",
       "       [ 0.95008842,  0.91224389,  0.91011459],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [-0.10321885, -0.09046709, -0.09009396],\n",
       "       [ 0.4105985 ,  0.40371618,  0.40340352],\n",
       "       [ 0.14404357,  0.1855722 ,  0.18550713],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [ 0.76103773,  0.8096924 ,  0.80794239],\n",
       "       [ 0.12167502,  0.16937907,  0.16907169],\n",
       "       [ 0.44386323,  0.42813934,  0.42753083],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [ 1.49407907,  1.5803887 ,  1.57713163],\n",
       "       [-0.20515826, -0.13466159, -0.1348491 ],\n",
       "       [ 0.3130677 ,  0.33455137,  0.33372569],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [-2.55298982, -2.57077101, -2.5637126 ],\n",
       "       [ 0.6536186 ,  0.69204522,  0.6927647 ],\n",
       "       [ 0.8644362 ,  0.86878803,  0.86924219],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [ 2.26975462,  2.34925969,  2.3421607 ],\n",
       "       [-1.45436567, -1.47031258, -1.4703182 ],\n",
       "       [ 0.04575852, -0.01797388, -0.01972268],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [ 1.53277921,  1.63782881,  1.63511801],\n",
       "       [ 1.46935877,  1.56277552,  1.56128156],\n",
       "       [ 0.15494743,  0.16238417,  0.16245119],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [-0.88778575, -0.86976324, -0.86919826],\n",
       "       [-1.98079647, -1.94815402, -1.94675231],\n",
       "       [-0.34791215, -0.34469109, -0.34499857],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [ 1.23029068,  1.25135382,  1.24912238],\n",
       "       [ 1.20237985,  1.17332414,  1.17191291],\n",
       "       [-0.38732682, -0.411664  , -0.41112202],\n",
       "       [ 0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.c_[true_coeffs.reshape(-1), estimated_coeffs_ens.reshape(-1), estimated_coeffs_jax.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pyensmallen optimization time: 1.0235660076141357\n",
      "JAX optimization time: 2.4678776264190674\n",
      "\n",
      "Pyensmallen Mean Absolute Error: 0.026384408255362625\n",
      "JAX Mean Absolute Error: 0.025860388\n"
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "print(\"Pyensmallen optimization time:\", ens_time)\n",
    "print(\"JAX optimization time:\", jax_time)\n",
    "\n",
    "mae_ens = np.mean(np.abs(true_coeffs - estimated_coeffs_ens))\n",
    "mae_jax = np.mean(np.abs(true_coeffs - estimated_coeffs_jax))\n",
    "\n",
    "print(\"\\nPyensmallen Mean Absolute Error:\", mae_ens)\n",
    "print(\"JAX Mean Absolute Error:\", mae_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pyensmallen Accuracy: 0.7667\n",
      "JAX Accuracy: 0.76669997\n",
      "\n",
      "Pyensmallen Final Loss: 0.5785731\n",
      "JAX Final Loss: 0.57857406\n"
     ]
    }
   ],
   "source": [
    "def predict(coeffs, X):\n",
    "    logits = X @ coeffs\n",
    "    return np.argmax(logits, axis=1)\n",
    "\n",
    "\n",
    "accuracy_ens = np.mean(predict(estimated_coeffs_ens, X) == y)\n",
    "accuracy_jax = np.mean(predict(estimated_coeffs_jax, X) == y)\n",
    "\n",
    "print(\"\\nPyensmallen Accuracy:\", accuracy_ens)\n",
    "print(\"JAX Accuracy:\", accuracy_jax)\n",
    "\n",
    "final_loss_ens = loss(jax.device_put(estimated_coeffs_ens[:, :-1]), X_jax, y_jax)\n",
    "final_loss_jax = loss(estimated_coeffs_jax[:, :-1], X_jax, y_jax)\n",
    "\n",
    "print(\"\\nPyensmallen Final Loss:\", final_loss_ens)\n",
    "print(\"JAX Final Loss:\", final_loss_jax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
