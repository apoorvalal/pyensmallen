{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least Squares via L-BFGS in ensmallen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyensmallen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.51639859 0.94598022 0.23380001 0.55162275 0.97811966 0.24254699\n",
      " 0.64702478 0.70271041 0.26476461 0.77362184 0.7817448  0.36874977\n",
      " 0.72697004 0.06518613 0.72705723 0.38967364 0.03826155 0.39386005\n",
      " 0.0438693  0.72142769]\n"
     ]
    }
   ],
   "source": [
    "# Generate some random data for linear regression\n",
    "n, k = 1_000_000, 20\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(n, k)\n",
    "print(true_params := np.random.rand(k))\n",
    "y = X @ true_params + np.random.randn(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_objective(params, gradient):\n",
    "    params = params.reshape(-1, 1)\n",
    "    residuals = X @ params - y.reshape(-1, 1)\n",
    "    objective = np.sum(residuals**2)\n",
    "    grad = 2 * X.T @ residuals\n",
    "    gradient[:] = grad.flatten()\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyensmallen estimated parameters: [0.51556024 0.94691468 0.23404849 0.55121759 0.97818756 0.24338623\n",
      " 0.64700696 0.70195589 0.26487498 0.77280983 0.78267599 0.36787315\n",
      " 0.72791074 0.06571446 0.72615144 0.38766298 0.03820425 0.39468909\n",
      " 0.04304362 0.72195013]\n",
      "pyensmallen mean squared error: 6.530072513292412e-07\n",
      "CPU times: user 4.96 s, sys: 163 ms, total: 5.12 s\n",
      "Wall time: 342 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create an L-BFGS optimizer\n",
    "optimizer = pyensmallen.L_BFGS()\n",
    "# Optimize\n",
    "result = optimizer.optimize(linear_regression_objective,\n",
    "    np.zeros(k, dtype=np.float64))\n",
    "print(\"pyensmallen estimated parameters:\", result)\n",
    "print(\"pyensmallen mean squared error:\", np.mean((result - true_params)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.82 s, sys: 52.3 ms, total: 2.87 s\n",
      "Wall time: 433 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np_solution = np.linalg.lstsq(X, y, rcond=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy least squares solution: [0.51556024 0.94691468 0.23404849 0.55121759 0.97818756 0.24338623\n",
      " 0.64700696 0.70195589 0.26487498 0.77280983 0.78267599 0.36787315\n",
      " 0.72791074 0.06571446 0.72615144 0.38766298 0.03820425 0.39468909\n",
      " 0.04304362 0.72195013]\n",
      "Mean squared error (NumPy): 6.530072504955779e-07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"NumPy least squares solution:\", np_solution)\n",
    "print(\"Mean squared error (NumPy):\", np.mean((np_solution - true_params)**2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "econometrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
